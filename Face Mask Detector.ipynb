{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hello, Welcome to my Face Mask Detection System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, I'm Sriashika Addala. I'm always enthusiastic & energetic when it comes to artificial intelligence! This project is an expo of the skills I've gained. I have gained internet references, I didn't count exactly how many, but yes I did refer to a lot of projects. Because, machine learning has never been something that I'd understand completely in the first go! Haha, gigs later...\n",
    "* My project plan is basically:\n",
    "    - Learn to implement ML & DL concepts by putting them into practice.\n",
    "    - Build a base model that will run on any laptop using an IDE that can run python scripts/jupyter notebooks.\n",
    "    - Once the base model is built, I'd make good use of my time to explore my CCTV camera's features and figure out a way to connect it somehow so that I can deploy my ML model somewhere that connects the CCTV.\n",
    "    - Next steps include real-time implementation of the face mask detection system at my home with an integration of CCTV, mobile server/e-mail for notification purposes and automation ofcourse. I do not possess veteran skills in these fields as of now. But it's a challenge to myself to implement this real-time system as per my scheduled plan.\n",
    "\n",
    "### About the base project:\n",
    "\n",
    "#### Data\n",
    "So yes, I've used a dataset that contains two folders: one contains images of people with masks and the other without masks. We need to explore the dataset, play around with it, ensure it's clean enough to go into the oven for bake-time.\n",
    "Please visit the link to download this dataset: https://drive.google.com/drive/folders/1Z8oqunvcDZ7_9QyD-R0rIVZ9ftvck-GM\n",
    "\n",
    "#### Model\n",
    "I'm about to use the very famous CNN - Convolutional Neural Network model for my project. We shall customize the layers as per our requirements for the best possible accuracy and least possible error rate.\n",
    "\n",
    "#### Deployment\n",
    "Well, I was just looking out for options to implement this system after model training and evaluation; I think PyGame is the best man for my job! Stay tuned to experience it yourself.\n",
    "\n",
    "\n",
    "\\<Edited\\>: Sep 29 2020\n",
    "<br><br>\n",
    "I just thought of sharing my mountaineous journey ride to implement this system:\n",
    "- My family was the first to test and experience my face mask detection system. Needless to say, they were very happy.\n",
    "- I had also welcomed numerous amount of what-ifs and buts and this helped me bring lots of changes to my system.\n",
    "- Am still working on the real-time implementation part (I won't give up ;) )\n",
    "- No Wi-Fi, limited 1GB/day data with poor signals due to remote locations - My biggest headache.\n",
    "- No previously installed high-end libraries/frameworks such as: Tensorflow, OpenCV, Keras, Pygame, VS Code, Anaconda... (you can imagine what I had to go through)\n",
    "- Finally, some days were brighter than the other so I could peacefully use the internet without any breakdowns within limit ofcourse and I worked 48 hours in one day (Just kidding..) to make this possible.\n",
    "- Lessons learnt:\n",
    "     - How to make use of your lockdown period?\n",
    "     - How to build a ML/DL project from scratch?\n",
    "     - How to turn your creative imagination into reality?\n",
    "     - How to work 48 hours in one day?\n",
    "     - How to manage time, stress and most importantly internet usage???\n",
    "- Do I sound funny to you? Well it may, but yeah its these challenging times that give us a lifetime's learning. Am glad I had to face multiple challenges at various scales.\n",
    "- Good day! :)\n",
    "\n",
    "\\<Edited\\>: Oct 20 2020\n",
    "<br><br>\n",
    "Hello, just a minor update: I am transfering this project to github!!! So the code has been updated accordingly. Thanks :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing dataset & essential libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import math\n",
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = r\"dataset/\"\n",
    "labels = dict(zip(os.listdir(dataset_path), [i for i in range(len(os.listdir(dataset_path)))]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring, visualizing and wrangling our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a block to explore and set our data & labels along with a little bit of image resizing and transformation\n",
    "image_size=100\n",
    "data,target=[],[]\n",
    "\n",
    "for category in labels.keys():\n",
    "    path = os.path.join(dataset_path,category)\n",
    "    image_names = os.listdir(path)\n",
    "    for name in image_names:\n",
    "        image_path = os.path.join(path,name)\n",
    "        image = cv2.imread(image_path)\n",
    "        try:\n",
    "            grey = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "            resized_image = cv2.resize(gray,(image_size,image_size))\n",
    "            data.append(resized_image)\n",
    "            target.append(labels[category])\n",
    "        except Exception as e:\n",
    "            print('Exception:',e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a block to demonstrate data wrangling by rescaling the images\n",
    "data = np.array(data)/255.0\n",
    "data = np.reshape(data,(data.shape[0],image_size,image_size,1))\n",
    "target = np.array(target)\n",
    "new_target = np_utils.to_categorical(target)\n",
    "np.save('images.npy',data)\n",
    "np.save('lables.npy',new_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building our CNN model with customized layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('images.npy')\n",
    "new_target = np.load('labels.npy')\n",
    "model = keras.Sequential(\n",
    "    Conv2D(200,(3,3),input_shape=data.shape[1:],activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "    Conv2D(100,(3,3),activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "    Flatten(),\n",
    "    Dropout(0.5), # Dropout to avoid overfitting\n",
    "    Dense(50,activation='relu'), # 64 neurons\n",
    "    Dense(2,activation='softmax')\n",
    ")\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.plot_model(model,'model.png',show_layer_names=True,show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arranging base setup for training, testing and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, train_target, test_target = train_test_split(data,new_target,test_size=0.1)\n",
    "checkpoint = ModelCheckpoint('model-{epoch:03d}.model',monitor='val_loss',verbose=0,save_best_only=True,mode='auto')\n",
    "history = model.fit(train_data,train_target,epochs=100,callbacks=[checkpoint],validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphical analysis of model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(N):\n",
    "    plt.style.use(\"ggplot\")\n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(0, N), history.history[\"loss\"], label=\"train_loss\")\n",
    "    plt.plot(np.arange(0, N), history.history[\"val_loss\"], label=\"val_loss\")\n",
    "    plt.plot(np.arange(0, N), history.history[\"accuracy\"], label=\"train_acc\")\n",
    "    plt.plot(np.arange(0, N), history.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "    plt.title(\"Training Loss and Accuracy\")\n",
    "    plt.xlabel(\"Epoch #\")\n",
    "    plt.ylabel(\"Loss/Accuracy\")\n",
    "    plt.legend(loc=\"center right\")\n",
    "    plt.savefig(\"CNN_Model\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
